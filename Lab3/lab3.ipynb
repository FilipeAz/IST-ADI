{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory 3: Partially observable Markov decision problems\n",
    "\n",
    "In the end of the lab, you should submit all code/answers written in the tasks marked as \"Activity n. XXX\", together with the corresponding outputs and any replies to specific questions posed to the e-mail <adi.tecnico@gmail.com>. Make sure that the subject is of the form [&lt;group n.&gt;] LAB &lt;lab n.&gt;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modeling\n",
    "\n",
    "Consider once again the princess saving problem described in the Homework and which you described as a POMDP.\n",
    "\n",
    "Recall that:\n",
    "\n",
    "* The princess can be in any one of two towers: Tower *A* and Tower *B*. The knight must decide which tower do invade to rescue the princess. \n",
    "\n",
    "* The knight can try to _peer_ at the towers, to figure out where the princess may be. \n",
    "\n",
    "* When the agent peers, it sees the princess in the right location with a probability of 0.9, and at the wrong location with probability 0.1.\n",
    "\n",
    "* Whenever the knight invades a tower, the \"world\" resets.\n",
    "\n",
    "Consider throughout that $\\gamma=0.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Implement your POMDP in Python. In particular,\n",
    "\n",
    "* Create a list with all the states;\n",
    "* Create a list with all the actions;\n",
    "* Create a list with all the observations\n",
    "* For each action, define a `numpy` array with the corresponding transition probabilities;\n",
    "* For each action, define a `numpy` array with the corresponding observation probabilities;\n",
    "* Define a `numpy` array with the cost describing the problem. Make sure that the costs lie in the interval [0,1] and that the cost for peering is in the middle between the cost for saving and being captured.\n",
    "\n",
    "The order for the states and actions used in the transition probability and cost matrices should match that in the lists of states and actions. \n",
    "\n",
    "**Note**: Don't forget to import `numpy`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "states = ['A', 'B']\n",
    "actions = ['a', 'b', 'p']\n",
    "obs = ['A', 'B', 'N']\n",
    "\n",
    "Pa = Pb = np.array([[0.5, 0.5],\n",
    "                    [0.5, 0.5]])\n",
    "\n",
    "Pp = np.array([[1.0, 0.0],\n",
    "               [0.0, 1.0]])\n",
    "\n",
    "P_dict = {'a': Pa, 'b': Pb, 'p': Pp}\n",
    "\n",
    "Oa = Ob = np.array([[0.0, 0.0, 1.0],\n",
    "                    [0.0, 0.0, 1.0]])\n",
    "\n",
    "Op = np.array([[0.9, 0.1, 0.0],\n",
    "               [0.1, 0.9, 0.0]])\n",
    "\n",
    "C = np.array([[0.0, 1.0, 0.5],\n",
    "              [1.0, 0.0, 0.5]]) \n",
    "\n",
    "O_dict = {'a': Oa, 'b': Ob, 'p': Op}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sampling\n",
    "\n",
    "You are now going to sample random trajectories of your POMDP and observe the impact it has on the corresponding belief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 2.\n",
    "\n",
    "Generate a random POMDP trajectory using a uniformly random policy. In particular, from a random initial state $x_0$ generate:\n",
    "\n",
    "1. A sequence of 10,000 states by selecting the actions uniformly at random;\n",
    "2. The corresponding sequence of 10,000 actions;\n",
    "3. The corresponding sequence of 10,000 observations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sequence_states = np.zeros(10000, dtype=str)\n",
    "sequence_actions = np.zeros(10000, dtype=str)\n",
    "sequence_observations = np.zeros(10000, dtype=str)\n",
    "\n",
    "sequence_states[0] = random.choice(states)\n",
    "sequence_actions[0] = random.choice(actions)\n",
    "\n",
    "if sequence_actions[0] == 'a' or sequence_actions[0] == 'b':\n",
    "    sequence_observations[0] = 'N'\n",
    "else:\n",
    "    sequence_observations[0] = np.random.choice(obs, 1, p = Op[0 if sequence_states[0] == 'A' else 1].tolist())[0]\n",
    "\n",
    "for i in range(1,10000):\n",
    "    if sequence_actions[i-1] == 'p':\n",
    "        sequence_states[i] = sequence_states[i-1]\n",
    "    else:\n",
    "        sequence_states[i] = np.random.choice(states, 1, p = Pa[0 if sequence_states[i-1] == 'A' else 1].tolist())[0]\n",
    "    \n",
    "    sequence_actions[i] = random.choice(actions)\n",
    "    \n",
    "    if sequence_actions[i] == 'a' or sequence_actions[i] == 'b':\n",
    "        sequence_observations[i] = 'N'\n",
    "    else:\n",
    "        sequence_observations[i] = np.random.choice(obs, 1, p = Op[0 if sequence_states[i] == 'A' else 1].tolist())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 3.\n",
    "\n",
    "For the POMDP trajectory generated in Activity 2, compute the corresponding sequence of beliefs, assuming that the initial belief is $\\mathbf{b}_0=[0.5, 0.5]$. Report the resulting beliefs, ignoring duplicate beliefs or beliefs whose distance is smaller than $10^{-3}$.\n",
    "\n",
    "**Note 1:** You may want to define a function `belief_update` that receives a belief, an action and an observation and returns the updated belief.\n",
    "\n",
    "**Note 2:** To compute the distance between vectors, you may find useful `numpy`'s function `linalg.norm`.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.5       ]\n",
      " [0.1        0.9       ]\n",
      " [0.01219512 0.98780488]\n",
      " [0.00136986 0.99863014]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "obs_col_dict = {'A': 0, 'B': 1, 'N': 2}\n",
    "\n",
    "init_belief = np.array([[0.5, 0.5]])\n",
    "\n",
    "sequence_beliefs = np.array(init_belief)\n",
    "\n",
    "def belief_update(belief, action, observation):\n",
    "    aux1 = belief.dot(P_dict[action])\n",
    "    aux2 = aux1.dot(np.diag(O_dict[action][:,obs_col_dict[observation]]))\n",
    "    new_belief = normalize(aux2.reshape(1,2), norm='l1')\n",
    "    return new_belief\n",
    "\n",
    "'''beliefs estão relacionados com a ação ou com o valor?'''\n",
    "for i in range(10000):\n",
    "    flag = False\n",
    "    new_belief = belief_update(sequence_beliefs[-1], sequence_actions[i], sequence_observations[i])\n",
    "    for old_belief in sequence_beliefs:\n",
    "        if np.linalg.norm(old_belief-new_belief) < 10e-3:\n",
    "            flag = True\n",
    "            break \n",
    "    if new_belief not in sequence_beliefs and not flag:\n",
    "        sequence_beliefs = np.append(sequence_beliefs, new_belief, axis=0)\n",
    "print(sequence_beliefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Solution methods\n",
    "\n",
    "In this section you are going to compare different non-exact solution methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 4\n",
    "\n",
    "Compute the solution for the underlying MDP and report the corresponding optimal policy and optimal cost-to-go. \n",
    "\n",
    "** Note:** You may reuse code from previous labs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-77be23d1fb97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mpinew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mpinew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mQa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mpinew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mQa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mpinew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mQa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     return _methods._amin(a, axis=axis,\n\u001b[1;32m-> 2420\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "'''P = np.squeeze(np.asarray(m2))\n",
    "J = np.zeros((6,1))\n",
    "print(P)\n",
    "gamma = Y\n",
    "err = 1\n",
    "i = 0\n",
    "\n",
    "initial_time = time.time()\n",
    "\n",
    "while err > 1e-8:\n",
    "    QUp = C + Y*PUp.dot(J)\n",
    "    QDown = C + Y*PDown.dot(J)\n",
    "    QLeft = C + Y*PLeft.dot(J)\n",
    "    QRight = C + Y*PRight.dot(J)\n",
    "    Jnew = np.min((QUp, QDown, QLeft, QRight), axis=0)\n",
    "    err = np.linalg.norm(Jnew - J)\n",
    "    i += 1\n",
    "    J = Jnew\n",
    "J_final = J\n",
    "print(J_final)\n",
    "print(\"Number of interations:\",i)\n",
    "\n",
    "print(\"Time:\", time.time() - initial_time)'''\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "pi = np.ones((2,3))\n",
    "\n",
    "quit = False\n",
    "\n",
    "#initial_time = time.time()\n",
    "\n",
    "Y = 0.9\n",
    "\n",
    "while not quit:\n",
    "    cpi = np.diag(pi[:,0]).dot(C) + np.diag(pi[:,1]).dot(C) + np.diag(pi[:,2]).dot(C)\n",
    "    Ppi = np.diag(pi[:,0]).dot(Pa) + np.diag(pi[:,1]).dot(Pb) + np.diag(pi[:,2]).dot(Pp)\n",
    "    J = np.linalg.inv(np.eye(2) - Y*Ppi).dot(cpi)\n",
    "    \n",
    "    Qa = np.transpose(C[:,0].reshape((1,2))) + Y*Pa.dot(J),\n",
    "    Qb = np.transpose(C[:,1].reshape((1,2))) + Y*Pb.dot(J)\n",
    "    Qp = np.transpose(C[:,2].reshape((1,2))) + Y*Pp.dot(J)\n",
    "    \n",
    "    pinew = np.zeros((2,3))\n",
    "    \n",
    "    pinew[:, 0, None] = np.isclose(Qa, np.min([Qa, Qb, Qp], axis=0), atol=1e-10, rtol=1e-10).astype(int)\n",
    "    pinew[:, 1, None] = np.isclose(Qb, np.min([Qa, Qb, Qp], axis=0), atol=1e-10, rtol=1e-10).astype(int)\n",
    "    pinew[:, 2, None] = np.isclose(Qp, np.min([Qa, Qb, Qp], axis=0), atol=1e-10, rtol=1e-10).astype(int)\n",
    "    \n",
    "    pinew = pinew / np.sum(pinew, axis=1, keepdims = True)\n",
    "    \n",
    "    quit = (pi == pinew).all()\n",
    "    pi = pinew\n",
    "\n",
    "print(pi)\n",
    "#print(\"Number of iterations:\", it)\n",
    "#print(\"Time:\", time.time() - initial_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 5\n",
    "\n",
    "For each of the beliefs computed in Activity 3, compute the action prescribed by:\n",
    "\n",
    "* The MLS heuristic;\n",
    "* The AV heuristic;\n",
    "* The Q-MDP heuristic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 6\n",
    "\n",
    "Suppose that the optimal cost-to-go function for the POMDP can be represented using the $\\alpha$-vectors\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{bmatrix}\n",
    "2.795\\\\\n",
    "3.795\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "3.795\\\\\n",
    "2.795\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "3.105\\\\\n",
    "3.105\n",
    "\\end{bmatrix}\\right\\}$$\n",
    "\n",
    "corresponding to the actions 'Invade Tower A', 'Invade Tower B' and 'Peer', respectively. Represent the optimal cost-to-go function and compare the optimal policy with the MDP heuristics from Activity 5 in the beliefs computed in Activity 3.\n",
    "\n",
    "** Note: ** Don't forget to import `matplotlib`, and use the magic `%matplotlib notebook`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert your code here."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
